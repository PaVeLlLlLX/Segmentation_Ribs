{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1zTxGkL-XzN_PSWyQTmFHzbR37XFh3kdP","authorship_tag":"ABX9TyM46nAmGF+Ps0Dg6LONCbjO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\n","%%shell\n","pip install -q cython\n","pip install -qU 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n","\n","pip install gdown\n","gdown --id 1HGnvRZW-HWkyh7x1_ZlvSAPDcx1OGlNh\n","gdown --id 1_HrcPnL5HnmG3m6XvQRK2IYAHf5a5mS_\n","unzip few_data_split.zip\n","\n","git clone https://github.com/comptech-winter-school/coal-composition-control -b dev\n"],"metadata":{"id":"xqEcvOwS_LoB","executionInfo":{"status":"ok","timestamp":1706179042717,"user_tz":-420,"elapsed":39107,"user":{"displayName":"C.G.A","userId":"13421874599689586520"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"52604478-be2a-4397-9405-e4b1df144a96"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.11.17)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n","/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Failed to retrieve file url:\n","\n","\tCannot retrieve the public link of the file. You may need to change\n","\tthe permission to 'Anyone with the link', or have had many accesses.\n","\n","You may still be able to access the file from the browser:\n","\n","\thttps://drive.google.com/uc?id=1HGnvRZW-HWkyh7x1_ZlvSAPDcx1OGlNh\n","\n","but Gdown can't. Please check connections and permissions.\n","/usr/local/lib/python3.10/dist-packages/gdown/cli.py:138: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1_HrcPnL5HnmG3m6XvQRK2IYAHf5a5mS_\n","To: /content/example.png\n","100% 1.16M/1.16M [00:00<00:00, 119MB/s]\n","unzip:  cannot find or open few_data_split.zip, few_data_split.zip.zip or few_data_split.zip.ZIP.\n","Cloning into 'coal-composition-control'...\n","remote: Enumerating objects: 1806, done.\u001b[K\n","remote: Counting objects: 100% (96/96), done.\u001b[K\n","remote: Compressing objects: 100% (15/15), done.\u001b[K\n","remote: Total 1806 (delta 85), reused 81 (delta 81), pack-reused 1710\u001b[K\n","Receiving objects: 100% (1806/1806), 31.92 MiB | 27.63 MiB/s, done.\n","Resolving deltas: 100% (1025/1025), done.\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["from packaging import version\n","import numpy as np\n","\n","if version.parse(np.__version__) >= version.parse(\"1.24.0\"):\n","  np.float = np.float64"],"metadata":{"id":"1G8-7gZWNFFT","executionInfo":{"status":"ok","timestamp":1706179042717,"user_tz":-420,"elapsed":4,"user":{"displayName":"C.G.A","userId":"13421874599689586520"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["%cd coal-composition-control\n","!pip install -qU numpy\n","!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zqv-eA5gXKEX","executionInfo":{"status":"ok","timestamp":1706179061063,"user_tz":-420,"elapsed":18349,"user":{"displayName":"C.G.A","userId":"13421874599689586520"}},"outputId":"e0c6ba73-ba59-41af-8609-fc2a934dede9"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/coal-composition-control\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision~=0.11.1 (from versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.12.0, 0.13.0, 0.13.1, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.16.2)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision~=0.11.1\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import torch\n","from PIL import Image\n","from pathlib import Path\n","from train.instance_segmentation.mask_rcnn_dataset import CoalFractionDataset"],"metadata":{"id":"w27J492KowzK","executionInfo":{"status":"ok","timestamp":1706179061506,"user_tz":-420,"elapsed":446,"user":{"displayName":"C.G.A","userId":"13421874599689586520"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import os\n","import random\n","\n","def seed_everything(SEED=411, seed_all=False) -> None:\n","    random.seed(SEED)\n","    np.random.seed(SEED)\n","    torch.manual_seed(SEED)\n","    torch.cuda.manual_seed(SEED)\n","    torch.backends.cudnn.deterministic = True\n","    os.environ['PYTHONHASHSEED']=str(SEED)\n","    if seed_all:\n","        torch.cuda.manual_seed_all(SEED)\n","        torch.backends.cudnn.benchmark = False"],"metadata":{"id":"qLNxQjzPWPbG","executionInfo":{"status":"ok","timestamp":1706179061507,"user_tz":-420,"elapsed":2,"user":{"displayName":"C.G.A","userId":"13421874599689586520"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import torchvision\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n","\n","\n","def get_instance_segmentation_model(num_classes):\n","    # load an instance segmentation model pre-trained on COCO\n","    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n","\n","    # get the number of input features for the classifier\n","    in_features = model.roi_heads.box_predictor.cls_score.in_features\n","    # replace the pre-trained head with a new one\n","    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","    # now get the number of input features for the mask classifier\n","    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n","    hidden_layer = 256\n","    # and replace the mask predictor with a new one\n","    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n","                                                       hidden_layer,\n","                                                       num_classes)\n","\n","    return model"],"metadata":{"id":"_TvHVi3z4VlP","executionInfo":{"status":"ok","timestamp":1706179064483,"user_tz":-420,"elapsed":2978,"user":{"displayName":"C.G.A","userId":"13421874599689586520"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["%%shell\n","\n","# Download TorchVision repo to use some files from\n","# references/detection\n","git clone https://github.com/pytorch/vision.git\n","cd vision\n","git checkout v0.11.0\n","\n","\n","cp references/detection/utils.py ../\n","cp references/detection/transforms.py ../\n","cp references/detection/coco_eval.py ../\n","cp references/detection/engine.py ../\n","cp references/detection/coco_utils.py ../"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6FT_s9Gop-BQ","executionInfo":{"status":"ok","timestamp":1706179188716,"user_tz":-420,"elapsed":124237,"user":{"displayName":"C.G.A","userId":"13421874599689586520"}},"outputId":"eba21d82-d22d-4d5e-d183-c4979764c4fe"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'vision'...\n","remote: Enumerating objects: 459044, done.\u001b[K\n","remote: Counting objects: 100% (39503/39503), done.\u001b[K\n","remote: Compressing objects: 100% (1826/1826), done.\u001b[K\n","remote: Total 459044 (delta 37668), reused 39399 (delta 37618), pack-reused 419541\u001b[K\n","Receiving objects: 100% (459044/459044), 904.51 MiB | 28.02 MiB/s, done.\n","Resolving deltas: 100% (426767/426767), done.\n","Note: switching to 'v0.11.0'.\n","\n","You are in 'detached HEAD' state. You can look around, make experimental\n","changes and commit them, and you can discard any commits you make in this\n","state without impacting any branches by switching back to a branch.\n","\n","If you want to create a new branch to retain commits you create, you may\n","do so (now or later) by using -c with the switch command. Example:\n","\n","  git switch -c <new-branch-name>\n","\n","Or undo this operation with:\n","\n","  git switch -\n","\n","Turn off this advice by setting config variable advice.detachedHead to false\n","\n","HEAD is now at 58a60b2eb4 Fixing bug on SSD backbone freezing. (#4591)\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["from engine import train_one_epoch, evaluate\n","import utils\n","import transforms as T\n","\n","\n","def get_transform(train):\n","    transforms = []\n","    # converts the image, a PIL image, into a PyTorch Tensor\n","    transforms.append(T.ToTensor())\n","    if train:\n","        # during training, randomly flip the training images\n","        # and ground-truth for data augmentation\n","        transforms.append(T.RandomHorizontalFlip(p=0.2))\n","        transforms.append(T.RandomPhotometricDistort(p=0.1))\n","\n","    return T.Compose(transforms)"],"metadata":{"id":"K3MePSNep-Fc","executionInfo":{"status":"ok","timestamp":1706179188717,"user_tz":-420,"elapsed":4,"user":{"displayName":"C.G.A","userId":"13421874599689586520"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","\n","dataset = CoalFractionDataset(\n","    root='/content/drive/MyDrive/dataset',\n","    vgg_json='/content/drive/MyDrive/via_project_25Jan2024_1h34m_json.json',\n","    width=2000,\n","    height=1500,\n","    transforms=get_transform(train=True)\n","    )\n","data_loader = torch.utils.data.DataLoader(\n","    dataset, batch_size=2, shuffle=True, num_workers=2,\n","    collate_fn=utils.collate_fn\n",")\n","# For Training\n","images, targets = next(iter(data_loader))\n","images = list(image for image in images)\n","targets = [{k: v for k, v in t.items()} for t in targets]\n","output = model(images, targets)   # Returns losses and detections\n","# For inference\n","model.eval()\n","x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n","predictions = model(x)           # Returns predictions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CdXHF1lChLMW","executionInfo":{"status":"ok","timestamp":1706179243042,"user_tz":-420,"elapsed":54328,"user":{"displayName":"C.G.A","userId":"13421874599689586520"}},"outputId":"f0eac472-2b80-4a24-f33d-fff9848c47c1"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n","100%|██████████| 160M/160M [00:01<00:00, 98.4MB/s]\n"]}]},{"cell_type":"code","source":["# use our dataset and defined transformations\n","dataset = CoalFractionDataset(\n","    root='/content/drive/MyDrive/dataset',\n","    vgg_json='/content/drive/MyDrive/via_project_25Jan2024_1h34m_json.json',\n","    width=2000,\n","    height=1500,\n","    transforms=get_transform(train=True)\n","    )\n","dataset_test = CoalFractionDataset(\n","    root='/content/drive/MyDrive/dataset_test',\n","    vgg_json='/content/drive/MyDrive/via_project_25Jan2024_1h18m_json.json',\n","    width=3000,\n","    height=2500,\n","    transforms=get_transform(train=False)\n","    )\n","\n","\n","# define training and validation data loaders\n","data_loader = torch.utils.data.DataLoader(\n","    dataset, batch_size=2, shuffle=True, num_workers=2,\n","    collate_fn=utils.collate_fn)\n","\n","data_loader_test = torch.utils.data.DataLoader(\n","    dataset_test, batch_size=1, shuffle=False, num_workers=2,\n","    collate_fn=utils.collate_fn)"],"metadata":{"id":"8PdfRBZTp-JF","executionInfo":{"status":"ok","timestamp":1706179243450,"user_tz":-420,"elapsed":410,"user":{"displayName":"C.G.A","userId":"13421874599689586520"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["from google.colab.patches import cv2_imshow\n","print(dataset.masks['00a2145de1886cb9eb88869c85d74080.dicom.jpg'])\n","print(dataset.size)\n","blank = np.zeros((2000, 1500))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6iEj_K0fWMGW","executionInfo":{"status":"ok","timestamp":1706179243450,"user_tz":-420,"elapsed":3,"user":{"displayName":"C.G.A","userId":"13421874599689586520"}},"outputId":"51c03349-02db-45c7-d7a3-a6dd18ae13f3"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["[((219, 1154), (224, 1072), (251, 1002), (301, 942), (383, 899), (455, 875), (540, 858), (614, 848), (687, 843), (783, 853), (860, 872), (920, 894), (969, 928), (945, 1014), (913, 988), (872, 942), (819, 920), (757, 911), (672, 906), (595, 913), (479, 935), (393, 964), (311, 1005), (279, 1055), (260, 1096), (265, 1111), (219, 1154))]\n","{'width': 2000, 'height': 1500}\n"]}]},{"cell_type":"code","source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","\n","num_classes = 2\n","\n","# get the model using our helper function\n","model = get_instance_segmentation_model(num_classes)\n","# move model to the right device\n","model.to(device)\n","\n","# construct an optimizer\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005,\n","                            momentum=0.9, weight_decay=0.0005)\n","\n","# and a learning rate scheduler which decreases the learning rate by\n","# 10x every 3 epochs\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n","                                               step_size=3,\n","                                               gamma=0.1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ATYH92_8AR9","executionInfo":{"status":"ok","timestamp":1706179245565,"user_tz":-420,"elapsed":2117,"user":{"displayName":"C.G.A","userId":"13421874599689586520"}},"outputId":"0c16ef41-05ed-42df-eb32-a18aad8c6fd0"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n","100%|██████████| 170M/170M [00:01<00:00, 121MB/s]\n"]}]},{"cell_type":"code","source":["import shutil\n","fol_path = '/content/drive/MyDrive/dataset/.ipynb_checkpoints'\n","if os.path.exists(fol_path):\n","  shutil.rmtree(fol_path)\n","\n","fold_path = '/content/drive/MyDrive/dataset_test/.ipynb_checkpoints'\n","if os.path.exists(fold_path):\n","  shutil.rmtree(fold_path)"],"metadata":{"id":"QKjwJdw99aSs","executionInfo":{"status":"ok","timestamp":1706179245939,"user_tz":-420,"elapsed":375,"user":{"displayName":"C.G.A","userId":"13421874599689586520"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["from torch.optim.lr_scheduler import StepLR\n","num_epochs = 15\n","\n","for epoch in range(num_epochs):\n","    # train for one epoch, printing every 10 iterations\n","    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=2)\n","    # update the learning rate\n","    lr_scheduler.step()\n","    # evaluate on the test dataset\n","    evaluate(model, data_loader_test, device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ozB_HcqO8Aa9","outputId":"198e3ccf-72d4-482d-afd8-235b5a0fb788"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: [0]  [0/8]  eta: 0:06:41  lr: 0.000719  loss: 2.7232 (2.7232)  loss_classifier: 0.5488 (0.5488)  loss_box_reg: 0.0339 (0.0339)  loss_mask: 2.0141 (2.0141)  loss_objectness: 0.1229 (0.1229)  loss_rpn_box_reg: 0.0035 (0.0035)  time: 50.2444  data: 3.6214\n","Epoch: [0]  [2/8]  eta: 0:04:28  lr: 0.002146  loss: 2.7232 (2.6421)  loss_classifier: 0.5488 (0.5200)  loss_box_reg: 0.0339 (0.0288)  loss_mask: 2.0141 (1.8820)  loss_objectness: 0.2031 (0.1994)  loss_rpn_box_reg: 0.0162 (0.0120)  time: 44.8217  data: 1.2160\n","Epoch: [0]  [4/8]  eta: 0:02:59  lr: 0.003573  loss: 1.7531 (1.9327)  loss_classifier: 0.4234 (0.3786)  loss_box_reg: 0.0342 (0.0539)  loss_mask: 1.0761 (1.3445)  loss_objectness: 0.1229 (0.1465)  loss_rpn_box_reg: 0.0086 (0.0093)  time: 44.7570  data: 0.7316\n","Epoch: [0]  [6/8]  eta: 0:01:29  lr: 0.005000  loss: 1.7531 (2.2047)  loss_classifier: 0.2005 (0.2846)  loss_box_reg: 0.0342 (0.0485)  loss_mask: 1.0761 (1.7289)  loss_objectness: 0.1068 (0.1337)  loss_rpn_box_reg: 0.0086 (0.0090)  time: 44.9887  data: 0.5246\n","Epoch: [0]  [7/8]  eta: 0:00:41  lr: 0.005000  loss: 1.7531 (2.1806)  loss_classifier: 0.1327 (0.2508)  loss_box_reg: 0.0339 (0.0427)  loss_mask: 1.0761 (1.6639)  loss_objectness: 0.1068 (0.2125)  loss_rpn_box_reg: 0.0086 (0.0108)  time: 41.6139  data: 0.4595\n","Epoch: [0] Total time: 0:05:33 (41.6495 s / it)\n","creating index...\n","index created!\n","Test:  [0/7]  eta: 0:01:18  model_time: 10.0381 (10.0381)  evaluator_time: 0.0026 (0.0026)  time: 11.2525  data: 1.2115\n","Test:  [6/7]  eta: 0:00:07  model_time: 7.3348 (7.6063)  evaluator_time: 0.0016 (0.0018)  time: 7.8189  data: 0.1771\n","Test: Total time: 0:00:55 (7.8637 s / it)\n","Averaged stats: model_time: 7.3348 (7.6063)  evaluator_time: 0.0016 (0.0018)\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n","Accumulating evaluation results...\n","DONE (t=0.00s).\n","IoU metric: bbox\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","IoU metric: segm\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","Epoch: [1]  [0/8]  eta: 0:07:02  lr: 0.005000  loss: 1.0847 (1.0847)  loss_classifier: 0.0206 (0.0206)  loss_box_reg: 0.0013 (0.0013)  loss_mask: 0.7853 (0.7853)  loss_objectness: 0.2697 (0.2697)  loss_rpn_box_reg: 0.0078 (0.0078)  time: 52.8427  data: 1.8582\n","Epoch: [1]  [2/8]  eta: 0:04:20  lr: 0.005000  loss: 0.9712 (0.9618)  loss_classifier: 0.0337 (0.0408)  loss_box_reg: 0.0092 (0.0105)  loss_mask: 0.7853 (0.7485)  loss_objectness: 0.1381 (0.1555)  loss_rpn_box_reg: 0.0060 (0.0065)  time: 43.4269  data: 0.6274\n"]}]},{"cell_type":"code","source":["model.eval()\n","model.roi_heads.score_thresh=0.5\n","model.roi_heads.nms_thresh=0.2"],"metadata":{"id":"PMgwMlH7PT4V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model, '/content/sample_data/mask-rcnn.pth')\n","# model = torch.load('/content/mask-rcnn.pth')"],"metadata":{"id":"O6VRWeUGXt_8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pick one image from the test set\n","# img, _ = dataset_test[0]\n","to_tensor = T.ToTensor()\n","img, _ = to_tensor(Image.open('/content/drive/MyDrive/333.jpg').convert(\"RGB\"))\n","# put the model in evaluation mode\n","model.eval()\n","with torch.no_grad():\n","    prediction = model([img.to(device)])"],"metadata":{"id":"eTVI-yYq39VN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prediction[0]['masks'].shape"],"metadata":{"id":"4lxqAsvG39YG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torchvision.transforms as transforms\n","from torchvision.utils import draw_segmentation_masks, draw_bounding_boxes\n","\n","to_pil_image = transforms.ToPILImage()\n","byte_img = img.mul(255).byte()"],"metadata":{"id":"CdfLHuqf39bE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def mask_on_image(byte_img, prediction, th=0.7):\n","  masks = torch.squeeze(prediction[0]['masks']).cpu()\n","  threshold = torch.Tensor([th])\n","  masks = (masks > threshold).bool()\n","  masks_on_image = draw_segmentation_masks(\n","      image = byte_img,\n","      masks = masks,\n","      alpha=0.6\n","      )\n","  return to_pil_image(masks_on_image)"],"metadata":{"id":"7Xhpu0Q839d8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def box_on_image(byte_img, prediction):\n","  boxes = torch.squeeze(prediction[0]['boxes'])\n","  boxes_on_image = draw_bounding_boxes(\n","      image=byte_img,\n","      boxes=boxes,\n","      width=4\n","      )\n","  return to_pil_image(boxes_on_image)"],"metadata":{"id":"TqwHD87Y39gz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["to_pil_image(byte_img)"],"metadata":{"id":"nVxP7MTh4GIj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["box_on_image(byte_img, prediction)"],"metadata":{"id":"kCW1ExIr4GNn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mask_on_image(byte_img, prediction, th=0.9)\n","mask_on_image(byte_img, prediction, th=0.8)\n","mask_on_image(byte_img, prediction, th=0.7)\n","mask_on_image(byte_img, prediction, th=0.6)\n","mask_on_image(byte_img, prediction, th=0.5)\n","mask_on_image(byte_img, prediction, th=0.4)\n","mask_on_image(byte_img, prediction, th=0.3)\n","mask_on_image(byte_img, prediction, th=0.2)\n","mask_on_image(byte_img, prediction, th=0.1)"],"metadata":{"id":"3ydk_9bT4GRa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mask_on_image(byte_img, prediction, th=0.1)"],"metadata":{"id":"c2F19XBkUrsr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -rf find -type d -name .ipynb_checkpoints"],"metadata":{"id":"d1cERFWX_zpU"},"execution_count":null,"outputs":[]}]}